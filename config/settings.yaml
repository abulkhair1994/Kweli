# Impact Learners ETL Configuration

# =============================================================================
# Data Source Configuration
# =============================================================================
data_source:
  # Source type: "csv" or "mysql"
  type: "csv"  # Change to "mysql" for production

  # CSV source configuration
  csv:
    path: "data/raw/impact_learners_profile-1759316791571.csv"

  # MySQL source configuration
  # Note: Credentials should be in environment variables, not here
  mysql:
    host: "prod-impact-tracking-mysql.cylzdy8g0gui.eu-west-1.rds.amazonaws.com"
    port: 3306
    database: "prod_impact_tracking"
    table: "impact_learners_profile"
    use_ssl: true
    connection_timeout: 120  # Connection establishment timeout
    read_timeout: 3600  # 1 hour - streaming keeps connection open
    pool_size: 3
    max_retries: 3  # Retry transient MySQL failures
    retry_delay: 5.0  # Initial retry delay (exponential backoff)

    # Read mode: "streaming" (recommended) or "offset"
    # - streaming: Single table scan with unbuffered cursor, O(N) time
    #              Best for tables WITHOUT indexes (like this one!)
    # - offset: LIMIT/OFFSET pagination, O(NÂ²) time for unindexed tables
    read_mode: "streaming"

  # Common settings
  # Note: Larger chunks are fine with streaming mode
  chunk_size: 10000  # Larger chunks with streaming mode

# =============================================================================
# ETL Pipeline Configuration
# =============================================================================
etl:
  chunk_size: 50000  # Rows to process per chunk (5x increase for performance)
  batch_size: 5000   # Records to send to Neo4j per batch (5x increase for performance)
  num_workers: 1     # Single worker to prevent relationship deadlocks on shared entities

  # Resume capability
  enable_checkpoints: true
  checkpoint_interval: 5000  # Save checkpoint every N rows

  # Progress tracking
  enable_progress_bar: false  # Disabled for maximum performance
  log_interval: 10000  # Log progress every N rows (reduced frequency)

# =============================================================================
# Neo4j Configuration
# =============================================================================
# For Aura, use neo4j+s:// scheme (encrypted)
# Credentials should be in environment variables: NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD
neo4j:
  # Connection details (can be overridden by environment variables)
  uri: "bolt://localhost:7688"  # For Aura: "neo4j+s://xxxx.databases.neo4j.io"
  user: "neo4j"
  password: "password123"  # Override with NEO4J_PASSWORD env var

  # Connection pooling (optimized for cloud)
  max_connection_pool_size: 30  # Reduced for cloud latency
  connection_timeout: 30  # seconds
  max_transaction_retry_time: 60  # seconds (increased for cloud)

  # Batch operations (optimized for cloud)
  batch_size: 1000  # Reduced from 5000 for cloud latency
  batch_timeout: 90  # seconds

  # Retry settings for transient errors
  max_retries: 3
  retry_delay: 1.0  # Initial delay, uses exponential backoff

validation:
  # Data quality thresholds
  max_error_rate: 0.05  # 5% max errors allowed
  required_fields:
    - sand_id
    - hashed_email
    - full_name

  # Date validation
  min_year: 1970
  max_year: 2030
  invalid_date_markers:
    - "1970-01-01"
    - "9999-12-31"

  # Numeric validation
  missing_value_markers:
    - -99
    - "-99"

transformers:
  # Skills parsing
  skills:
    delimiter: ","
    normalize: true
    max_skills_per_learner: 50

  # Geographic data
  geography:
    use_hybrid_approach: true  # Store as property + create nodes
    normalize_country_codes: true
    strict_country_validation: false  # Fail on unmapped countries (recommended: true for production)
    auto_generate_codes: true  # Fallback to [:2] for unmapped countries (disable in strict mode)
    required_mapping_coverage: 0.95  # Warn if <95% of countries are mapped

  # Temporal state tracking
  temporal:
    # Basic temporal tracking (snapshot mode)
    enable_learning_state_tracking: true
    enable_professional_status_tracking: true
    default_snapshot_date: "2025-10-06"

    # Temporal history tracking (SCD Type 2 mode)
    enable_learning_state_history: true  # Build full history from learning_details
    enable_professional_status_history: true  # Build full history from employment_details
    inactive_gap_months: 6  # Gap to consider learner inactive between programs
    unemployment_gap_months: 1  # Gap to consider unemployed between jobs
    infer_initial_unemployment: true  # Create unemployed status before first job

logging:
  level: INFO
  format: json
  handlers:
    - type: file
      filename: "data/logs/etl_{timestamp}.log"
    - type: console
      stream: stdout
